{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2T95A64AmTw"
   },
   "source": [
    "# **SolveMate : Your Personalized Math Partner**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xwyoa6WxBbCL"
   },
   "source": [
    "## **Introduction**\n",
    "\n",
    "**SolveMate** is an innovative math bot designed to provide quick, accurate, and intuitive solutions to mathematical problems. Powered by advanced AI and Hugging Face's state-of-the-art language models, SolveMate is equipped to understand natural language queries and generate clear, step-by-step responses.\n",
    "\n",
    " Its primary objective is to assist students, educators, and professionals in tackling a wide range of mathematical tasks, from basic arithmetic to complex algebraic equations. With a user-friendly interface and real-time interaction, SolveMate transforms the way users approach problem-solving, making mathematics more accessible and engaging.\n",
    "\n",
    " This project demonstrates the seamless integration of cutting-edge AI technology with practical applications in education and beyond."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w1p9QU_67V-H"
   },
   "source": [
    "## **Abstract**\n",
    "\n",
    "This project leverages Hugging Face's language models for interactive question-answering functionalities. The notebook integrates pre-trained transformers and user input to simulate a tutoring environment. It focuses on natural language understanding and generating helpful responses to user queries, making it suitable for tasks such as math tutoring or general question answering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2g-tDWh37egg"
   },
   "source": [
    "## **Theory**\n",
    "The underlying framework employs a causal language model provided by Hugging Face's transformers library. A causal model predicts the next word in a sequence given preceding words. Key components include:\n",
    "\n",
    "**AutoModelForCausalLM:** Used to load the pre-trained language model.\n",
    "\n",
    "**AutoTokenizer:** Converts text inputs into tokenized sequences compatible with the model. The model generates a sequence of tokens based on the user's query, showcasing its comprehension of context and logical reasoning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VU7UAjZ87vKG"
   },
   "source": [
    "## **What We Plan to Do**\n",
    "\n",
    "1. Set up the necessary dependencies and authenticate with Hugging Face.\n",
    "\n",
    "2. Load a pre-trained causal language model.\n",
    "\n",
    "3. Create an interactive interface where users can input queries.\n",
    "\n",
    "4. Process the user input and generate responses using the model.\n",
    "\n",
    "5. Observe and analyze the quality of the generated responses.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n3rFhuE079oY"
   },
   "source": [
    "## **Importing and Installing Required Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "e13e2e6374984749970a4d1f279add35",
      "bd98206b913146debee91e1821175ba2",
      "0d1d016dd8fa4316bbc07220411521b4",
      "689cad99b58740c093515b34512a54e3",
      "fde3a4a7b9cf46e7944a0f163d88c757",
      "1ab0e917f555471da674d6a229997460",
      "cbcc64b75e8a43759c79d8d955768d4d",
      "1c133feb418e4eb49642c65c686afb49",
      "2b1e5fe56bea48a6b19169c60081815a",
      "23b811329fc5468e9be3a90afeac6ba2",
      "2852abc08a2e402f92869352df4cce57",
      "70755ae571c949e3a9c27fd8fd3ad6d3",
      "eed3632dd1cd46759f18edac33c035d0",
      "ce049dd105af40be8c0f65a77319ab8c",
      "a885050160a24fffa451e084dfa7cf3c",
      "1a0519d55bdf46b29c1b47ec20195013",
      "b8403b160acb4d51b537d29c5032f8e0",
      "8073af677274438984b5fadebf75e5cd",
      "f4cdb2c12fed4f258f0cfc846f522dcd",
      "e57b5f8d83b94c74b7e93ac5a182764b"
     ]
    },
    "id": "cZncHqF-Ia54",
    "outputId": "8c4721d4-3df8-4140-deb6-b5aa40d62899"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e13e2e6374984749970a4d1f279add35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Install required libraries\n",
    "!pip install transformers accelerate bitsandbytes --quiet\n",
    "\n",
    "# Hugging Face Login\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176,
     "referenced_widgets": [
      "9e21d1ee5e4a498ab447dc9dcda0003b",
      "eb5d3b9b5d454eada8687b7568b8be75",
      "899661df821b4740a4e1b06ebca7286a",
      "82c9fec8070e42d49188279f32540e7a",
      "88b477cbb7b845ccbbd23a218114f216",
      "87dae2587790430d9cad04128fd90072",
      "1ee349c969564565a67aad8acb4a5a21",
      "eb08b54008764f85954f412833bd221c",
      "8382d85ba467400d909010a005ede1d3",
      "e14b7bbc33384e0bb1e5e219719209b9",
      "b4e4d8ff5dd74b1b81a5f12bd905cd0e"
     ]
    },
    "id": "nMOV4lRvIm7T",
    "outputId": "8a5ca232-9822-4723-e616-14bf2a33ec8d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e21d1ee5e4a498ab447dc9dcda0003b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Import necessary classes\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer # Import AutoModelForCausalLM and AutoTokenizer\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "        \"meta-llama/Llama-2-7b-chat-hf\",\n",
    "        device_map=\"auto\",  # Automatically map model across available hardware\n",
    "        torch_dtype=\"auto\",  # Use the most efficient precision\n",
    "        load_in_4bit=False    # Disable 4-bit loading to avoid CUDA dependency\n",
    "    )\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\") # Initialize tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wM-NEp_T8mnx"
   },
   "source": [
    "Here we initialize the \"Llama-2-7b-chat-hf\" language model from Meta using Hugging Face's transformers library.\n",
    "The AutoModelForCausalLM class is used to load the model, which supports causal language modeling tasks. The model is configured to automatically map across available hardware and use the most efficient precision for the device.\n",
    "Four-bit loading is disabled to avoid CUDA dependencies, ensuring compatibility across environments. The tokenizer, initialized with AutoTokenizer, handles input tokenization and output decoding for seamless interaction with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "oLgYbc_VND_w"
   },
   "outputs": [],
   "source": [
    "def ask_question(prompt, max_new_tokens=None):\n",
    "    \"\"\"\n",
    "    Generate a response from the model given a prompt.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The user's question.\n",
    "        max_new_tokens (int, optional): Maximum number of tokens in the response. Defaults to None for no explicit limit.\n",
    "\n",
    "    Returns:\n",
    "        str: The model's response prefixed with \"Response:\".\n",
    "    \"\"\"\n",
    "    # Move inputs to the same device as the model\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    # Generate response without a token limit\n",
    "    # Use model.config.max_position_embeddings instead of model.config.n_positions\n",
    "    outputs = model.generate(\n",
    "        inputs.input_ids,\n",
    "        max_new_tokens=max_new_tokens if max_new_tokens else model.config.max_position_embeddings - inputs.input_ids.size(1)\n",
    "    )\n",
    "\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Clean up whitespace in the response\n",
    "    response = response.strip()  # Remove leading/trailing whitespace\n",
    "    response = response.replace('\\n', ' ')  # Replace newlines with spaces\n",
    "\n",
    "    # Add \"Response:\" prefix to the response\n",
    "    return \"Response: \" + response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ApoDEYlr84Kx"
   },
   "source": [
    "The function `ask_question` here, generates a text-based response using the model based on a provided prompt.\n",
    "It takes two arguments: the user's question (`prompt`) and the maximum number of tokens in the response (`max_new_tokens`). The function tokenizes the input text and moves the resulting tensor to the GPU for processing.\n",
    "The model generates a response by predicting the next tokens up to the specified limit, which is then decoded back into human-readable text using the tokenizer.\n",
    "Finally, the function returns the decoded response, excluding any special tokens, to ensure clean and readable output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NjWdmsjh9u_J"
   },
   "source": [
    "## **Chat With SolveMaster**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sKMl_hjx9iWn"
   },
   "source": [
    "Now, further we introduce an interactive interface where users can input questions or prompts to communicate with the model.\n",
    "\n",
    "The `input()` function captures the user's query, which is then processed by the `ask_question` function to generate a response.\n",
    "\n",
    "The model analyzes the prompt, generates a coherent reply, and ensures the output is clean and easy to read.\n",
    "\n",
    "Finally, the generated response is printed, allowing users to view the model's answer in real-time.\n",
    "\n",
    "This setup enables a dynamic and engaging way to test the model's ability to handle diverse inputs effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rzj9JJI_NSJu",
    "outputId": "437b80e3-a3fa-4c5d-b3db-a92f3294075e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask Anything: What is Pythagorus Theorem? Explain with example.\n",
      "Response: What is Pythagorus Theorem? Explain with example. Pythagorean theorem is a fundamental concept in geometry that describes the relationship between the lengths of the sides of a right triangle. The theorem states that the square of the length of the hypotenuse (the side opposite the right angle) is equal to the sum of the squares of the lengths of the other two sides.  The theorem can be expressed mathematically as:  a^2 + b^2 = c^2  where a and b are the lengths of the other two sides of the triangle, and c is the length of the hypotenuse.  Here's an example to illustrate the theorem:  Consider a right triangle with sides of length 3, 4, and 5 units. Using the Pythagorean theorem, we can find the length of the hypotenuse (the side opposite the right angle):  a^2 + b^2 = c^2 3^2 + 4^2 = c^2 9 + 16 = c^2 25 = c^2  Therefore, the length of the hypotenuse is 5 units.  This theorem has many practical applications in geometry, trigonometry, and other fields, such as calculating the height of a building or the distance between two points in a triangle.\n"
     ]
    }
   ],
   "source": [
    "# Get user input\n",
    "user_prompt = input(\"Ask Anything: \")\n",
    "\n",
    "# Generate response\n",
    "response = ask_question(user_prompt)\n",
    "\n",
    "# Print the response\n",
    "print(response)  # Print the cleaned-up response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wyz_pjiWOHvO",
    "outputId": "68f60280-bbf6-44c4-f626-8554688221a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask Anything: \"Explain how to calculate the molar mass of a compound, providing hints for each step.\"\n",
      "Response: \"Explain how to calculate the molar mass of a compound, providing hints for each step.\"  Calculating the molar mass of a compound is an important concept in chemistry. It is the mass of one mole of a substance, and it is usually expressed in units of grams per mole (g/mol). Here are the steps to calculate the molar mass of a compound:  Step 1: Identify the compound The first step is to identify the compound for which you want to calculate the molar mass. Write the chemical formula of the compound.  Hint: The chemical formula of a compound is a shorthand way of representing the number and types of atoms present in one mole of the compound.  Step 2: Determine the atomic masses of the elements The next step is to determine the atomic masses of each element present in the compound. The atomic mass of an element is the mass of one atom of that element. You can find the atomic masses of elements in the periodic table or in a reference book.  Hint: The atomic mass of an element is usually expressed in units of u (unified atomic mass units), which are equal to 1/12 the mass of a carbon-12 atom.  Step 3: Add the atomic masses of the elements Once you have the atomic masses of all the elements in the compound, you need to add them up to get the total atomic mass of the compound.  Hint: When adding the atomic masses of the elements, you need to use the appropriate units. For example, if you are adding the atomic masses of hydrogen (H) and oxygen (O), you would use u (unified atomic mass units\n"
     ]
    }
   ],
   "source": [
    "# Get user input\n",
    "user_prompt = input(\"Ask Anything: \")\n",
    "\n",
    "# Generate response\n",
    "response = ask_question(user_prompt)\n",
    "\n",
    "# Print the response\n",
    "print(response)  # Print the cleaned-up response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2fubkOFDOR1Y",
    "outputId": "e9fd22da-c254-4423-8e42-891e894ea35d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask Anything: After explaining the causes of World War I, ask: â€˜What could have been done differently to prevent the war\n",
      "Response: After explaining the causes of World War I, ask: â€˜What could have been done differently to prevent the war?â€™  Published in 1919, this image shows the signing of the Treaty of Versailles, which officially ended World War I. The treaty imposed harsh penalties on Germany, which many historians believe contributed to the rise of Nazi Germany and the outbreak of World War II. (Image source: Library of Congress)  What could have been done differently to prevent the war?  There are several things that could have been done differently to prevent World War I:  1. Diplomacy: Diplomatic efforts could have been made to resolve conflicts between European nations through negotiations and agreements, rather than through military actions. 2. Arms control: Limiting the production and deployment of weapons, such as the implementation of the Treaty of London, could have reduced the risk of war. 3. International cooperation: Strengthening international organizations and cooperation could have helped to prevent the war by providing a framework for resolving conflicts peacefully. 4. Economic cooperation: Promoting economic cooperation and interdependence between nations could have reduced the likelihood of war by creating mutual interests and incentives for peace. 5. Appeasement policy: The policy of appeasement, where nations try to avoid conflict by giving in to the demands of aggressive powers, could have been pursued more vigorously to prevent the war. 6. Improved intelligence: Improving intelligence gathering and sharing could have helped to identify and prevent the assassination of Archduke Franz Ferdinand, which was the spark that ignited the war. 7. Strengthening the League of\n"
     ]
    }
   ],
   "source": [
    "# Get user input\n",
    "user_prompt = input(\"Ask Anything: \")\n",
    "\n",
    "# Generate response\n",
    "response = ask_question(user_prompt)\n",
    "\n",
    "# Print the response\n",
    "print(response)  # Print the cleaned-up response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Od55Nw986F40",
    "outputId": "7db5fbf1-99f4-4c8a-e1fd-e4e66d0d7e35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask Anything: Create a 5-question multiple-choice quiz on Newton's laws of motion and provide explanations for correct and incorrect answers.\n",
      "Response: Create a 5-question multiple-choice quiz on Newton's laws of motion and provide explanations for correct and incorrect answers.  Question 1: Which of the following is a consequence of Newton's first law of motion? A) An object at rest will remain at rest unless acted upon by an external force. B) An object in motion will continue to move in a straight line unless acted upon by an external force. C) An object will always maintain its initial velocity unless acted upon by an external force. D) An object will change its velocity if it is in a gravitational field.  Correct answer: A) An object at rest will remain at rest unless acted upon by an external force.  Explanation: Newton's first law of motion states that an object at rest will remain at rest unless acted upon by an external force. This means that an object will maintain its state of motion (either at rest or in motion) unless a force is applied to it.  Question 2: According to Newton's second law of motion, the force applied to an object is equal to its ________________. A) Mass times acceleration B) Acceleration times velocity C) Velocity times force D) Mass times velocity  Correct answer: A) Mass times acceleration.  Explanation: Newton's second law of motion states that the force applied to an object is equal to its mass times its acceleration. This means that the more massive an object is, the more force is required to produce a given acceleration.  Question 3: Which of the following is a consequence of Newton's third law of motion? A) For every action, there is an equal and opposite reaction. B) The momentum of an object\n"
     ]
    }
   ],
   "source": [
    "# Get user input\n",
    "user_prompt = input(\"Ask Anything: \")\n",
    "\n",
    "# Generate response\n",
    "response = ask_question(user_prompt)\n",
    "\n",
    "# Print the response\n",
    "print(response)  # Print the cleaned-up response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x8HtA8hk-MVf"
   },
   "source": [
    "## **Observations**\n",
    "\n",
    "The implementation successfully creates an interactive interface for users to engage with the model in real-time.\n",
    "\n",
    "The model processes user prompts effectively, generating coherent and contextually appropriate responses. The response generation is seamless, showcasing the model's ability to understand and process natural language inputs.\n",
    "\n",
    "However, the interaction heavily relies on the user providing clear and well-structured prompts for optimal results. Additionally, performance may vary based on the complexity of the query and the computational resources available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lcd2J_hK-esk"
   },
   "source": [
    "## **Conclusion**\n",
    "\n",
    "In conclusion, the implemented code demonstrates the effective use of a pre-trained language model for interactive query-response tasks.\n",
    "\n",
    "It provides a user-friendly interface where queries are processed and responses are generated in real-time, highlighting the model's natural language understanding capabilities.\n",
    "\n",
    "The integration of Hugging Face's tokenizer and model ensures smooth text processing and response generation. While the setup performs well for most inputs, optimizing prompts and ensuring sufficient computational resources can further enhance its performance.\n",
    "\n",
    "Overall, this implementation serves as a practical foundation for deploying conversational AI applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F2QNp4wD-2rW"
   },
   "source": [
    "## **References**\n",
    "\n",
    "1. Hugging Face Transformers\n",
    "Hugging Face Team. (2024).\n",
    "\n",
    "Transformers Documentation. Retrieved from https://huggingface.co/docs/transformers\n",
    "\n",
    "2. Meta LLaMA Model\n",
    "Meta AI. (2024).\n",
    "\n",
    "LLaMA: Open and Efficient Foundation Language Models. Retrieved from https://huggingface.co/meta-llama/Llama-2-7b-chat-hf\n",
    "\n",
    "3. BitsAndBytes Library\n",
    "Tim Dettmers. (2024).\n",
    "\n",
    "Bits and Bytes for Efficient Deep Learning. Retrieved from https://github.com/TimDettmers/bitsandbytes\n",
    "\n",
    "4. PyTorch Framework\n",
    "Paszke, A., et al. (2019).\n",
    "\n",
    "PyTorch: An Imperative Style, High-Performance Deep Learning Library. Retrieved from https://pytorch.org/\n",
    "\n",
    "5. Accelerate Library\n",
    "Hugging Face Team. (2024).\n",
    "\n",
    "Accelerate: Simplified Training and Inference. Retrieved from https://huggingface.co/docs/accelerate\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yrxWcpGF_fLr"
   },
   "source": [
    "## **MIT License**\n",
    "\n",
    "Copyright (c) 2024 Sanika Dhayabar Patil\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r0MesjbT_59a"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0d1d016dd8fa4316bbc07220411521b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "PasswordModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "PasswordModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "PasswordView",
      "continuous_update": true,
      "description": "Token:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_23b811329fc5468e9be3a90afeac6ba2",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_2852abc08a2e402f92869352df4cce57",
      "value": ""
     }
    },
    "1a0519d55bdf46b29c1b47ec20195013": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ab0e917f555471da674d6a229997460": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1a0519d55bdf46b29c1b47ec20195013",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_b8403b160acb4d51b537d29c5032f8e0",
      "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
     }
    },
    "1c133feb418e4eb49642c65c686afb49": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ee349c969564565a67aad8acb4a5a21": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "23b811329fc5468e9be3a90afeac6ba2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2852abc08a2e402f92869352df4cce57": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2b1e5fe56bea48a6b19169c60081815a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "689cad99b58740c093515b34512a54e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "CheckboxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "CheckboxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "CheckboxView",
      "description": "Add token as git credential?",
      "description_tooltip": null,
      "disabled": false,
      "indent": true,
      "layout": "IPY_MODEL_70755ae571c949e3a9c27fd8fd3ad6d3",
      "style": "IPY_MODEL_eed3632dd1cd46759f18edac33c035d0",
      "value": true
     }
    },
    "70755ae571c949e3a9c27fd8fd3ad6d3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8073af677274438984b5fadebf75e5cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f4cdb2c12fed4f258f0cfc846f522dcd",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_e57b5f8d83b94c74b7e93ac5a182764b",
      "value": "Connecting..."
     }
    },
    "82c9fec8070e42d49188279f32540e7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e14b7bbc33384e0bb1e5e219719209b9",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_b4e4d8ff5dd74b1b81a5f12bd905cd0e",
      "value": "â€‡2/2â€‡[00:57&lt;00:00,â€‡26.49s/it]"
     }
    },
    "8382d85ba467400d909010a005ede1d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "87dae2587790430d9cad04128fd90072": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "88b477cbb7b845ccbbd23a218114f216": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "899661df821b4740a4e1b06ebca7286a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eb08b54008764f85954f412833bd221c",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8382d85ba467400d909010a005ede1d3",
      "value": 2
     }
    },
    "9e21d1ee5e4a498ab447dc9dcda0003b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_eb5d3b9b5d454eada8687b7568b8be75",
       "IPY_MODEL_899661df821b4740a4e1b06ebca7286a",
       "IPY_MODEL_82c9fec8070e42d49188279f32540e7a"
      ],
      "layout": "IPY_MODEL_88b477cbb7b845ccbbd23a218114f216"
     }
    },
    "a885050160a24fffa451e084dfa7cf3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "b4e4d8ff5dd74b1b81a5f12bd905cd0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b8403b160acb4d51b537d29c5032f8e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bd98206b913146debee91e1821175ba2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1c133feb418e4eb49642c65c686afb49",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_2b1e5fe56bea48a6b19169c60081815a",
      "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
     }
    },
    "cbcc64b75e8a43759c79d8d955768d4d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": "center",
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "flex",
      "flex": null,
      "flex_flow": "column",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "50%"
     }
    },
    "ce049dd105af40be8c0f65a77319ab8c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e13e2e6374984749970a4d1f279add35": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [],
      "layout": "IPY_MODEL_cbcc64b75e8a43759c79d8d955768d4d"
     }
    },
    "e14b7bbc33384e0bb1e5e219719209b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e57b5f8d83b94c74b7e93ac5a182764b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "eb08b54008764f85954f412833bd221c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eb5d3b9b5d454eada8687b7568b8be75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_87dae2587790430d9cad04128fd90072",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_1ee349c969564565a67aad8acb4a5a21",
      "value": "Loadingâ€‡checkpointâ€‡shards:â€‡100%"
     }
    },
    "eed3632dd1cd46759f18edac33c035d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f4cdb2c12fed4f258f0cfc846f522dcd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fde3a4a7b9cf46e7944a0f163d88c757": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Login",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_ce049dd105af40be8c0f65a77319ab8c",
      "style": "IPY_MODEL_a885050160a24fffa451e084dfa7cf3c",
      "tooltip": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
