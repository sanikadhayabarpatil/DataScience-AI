{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Introduction to the Project**\n",
    "\n",
    "In today's digital world, credit card fraud has become a major concern, costing businesses and consumers billions of dollars every year. However, one of the biggest challenges in fraud detection is the extreme imbalance in dataâ€”fraudulent transactions are rare compared to legitimate ones. This project takes a deep dive into Credit Card Fraud Detection, a crucial yet often overlooked problem, and explores effective ways to handle imbalanced datasets.\n",
    "\n",
    "To build a reliable fraud detection system, we cannot rely on standard machine learning models. Without proper preprocessing, the model would be biased towards predicting all transactions as non-fraudulent, simply because fraudulent cases are so few. To address this, we employ techniques such as SMOTE (Synthetic Minority Over-sampling Technique) to balance the dataset, ensuring that our model can accurately distinguish between fraudulent and legitimate transactions.\n",
    "\n",
    "This project is not just about detecting fraud; it is about understanding data imbalance and mastering techniques to overcome it before training a classification model. By the end of this notebook, you will have a solid grasp of handling skewed data distributions and building more robust fraud detection systems.\n",
    "\n",
    "#### **Dataset Overview**\n",
    "The dataset used in this project consists of credit card transactions recorded in September 2013 by European cardholders. The transactions span over two days and contain a total of 284,807 records, out of which only 492 transactions are fraudulent. This means that the fraudulent cases make up a mere 0.172% of the entire dataset, making it highly imbalanced.\n",
    "\n",
    "Due to confidentiality reasons, the dataset only includes numerical features, which are the result of Principal Component Analysis (PCA) transformations. Hereâ€™s a breakdown of the key features:\n",
    "\n",
    "V1 to V28: Principal components extracted from PCA transformation.\n",
    "Time: The elapsed time (in seconds) between each transaction and the first transaction in the dataset.\n",
    "Amount: The transaction amount, which can be used for cost-sensitive learning.\n",
    "Class: The target variable, where:\n",
    "0 indicates a legitimate transaction.\n",
    "1 indicates a fraudulent transaction.\n",
    "Since the original feature names and additional background information about the dataset are confidential, we rely solely on these transformed variables for fraud detection. \n",
    "\n",
    "#### **Dataset Information**\n",
    "We are using the Credit Card Fraud Detection dataset, available on Kaggle:\n",
    "ðŸ”— Credit Card Fraud Dataset: https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud\n",
    "\n",
    "With our evaluation strategy in place, letâ€™s move forward and build a fraud detection model that does more than just predict \"no fraud\"â€”but actually detects fraud!\n",
    "\n",
    "#### **Evaluation Strategy**\n",
    "When dealing with highly imbalanced datasets, traditional accuracy metrics can be misleading. In fraud detection, where fraudulent transactions make up a tiny fraction of the data, a model predicting \"no fraud\" 99.8% of the time might still appear highly accurateâ€”yet it completely fails at identifying actual fraud cases.\n",
    "\n",
    "To ensure a meaningful evaluation, we will use the Area Under the Precision-Recall Curve (AUPRC) as our primary metric. Unlike standard accuracy or even AUC-ROC, AUPRC focuses on how well the model identifies positive cases (fraudulent transactions) while minimizing false positives, making it better suited for unbalanced classification problems.\n",
    "\n",
    "#### **Evaluation Approach**\n",
    "Given that this is a real-world dataset (not a Kaggle competition), we will allocate 0.2% of the data as our test set.\n",
    "\n",
    "This ensures that our model is evaluated on a small but representative subset of transactions, allowing us to measure its true ability to detect fraudulent activities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-06T16:57:47.756103Z",
     "iopub.status.busy": "2022-11-06T16:57:47.755512Z",
     "iopub.status.idle": "2022-11-06T16:57:50.888829Z",
     "shell.execute_reply": "2022-11-06T16:57:50.887521Z",
     "shell.execute_reply.started": "2022-11-06T16:57:47.755973Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing Libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "# Pre-Processing Libs\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modelling Libs\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Validating/Testing libs\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "print(\"Libraries Imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Loading the Data: Preparing for Fraud Detection**\n",
    "Since the dataset exceeds 100MB, it has been compressed into a ZIP file for efficient storage and transfer. Unfortunately, GitHub restricts files larger than 100MB, so we need to unzip the folder before we can start working with the data. This process can be easily handled using Pandas and Pythonâ€™s built-in utilities.\n",
    "\n",
    "**Steps for Data Loading & Exploration**\n",
    "* Extract the dataset: Unzip the file to access the raw data. Load the dataset using Pandas for further processing.\n",
    "* Explore the dataset: Display the first few rows to understand the structure. Check for missing values and data consistency.\n",
    "* Understand the dataset: Analyze basic information such as column names, data types, and null values. Examine dataset size and the distribution of fraud vs. non-fraud cases.\n",
    "* Summarize key statistics: Generate descriptive statistics for numerical features. Understand patterns in transaction amounts and time-based trends.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-06T16:57:50.892346Z",
     "iopub.status.busy": "2022-11-06T16:57:50.891522Z",
     "iopub.status.idle": "2022-11-06T16:57:56.106509Z",
     "shell.execute_reply": "2022-11-06T16:57:56.105242Z",
     "shell.execute_reply.started": "2022-11-06T16:57:50.892297Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read the dataset using the compression zip\n",
    "credit_df = pd.read_csv(\"../input/creditcardfraud/creditcard.csv\")\n",
    " \n",
    "# Display dataset\n",
    "credit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-06T16:57:56.108526Z",
     "iopub.status.busy": "2022-11-06T16:57:56.108199Z",
     "iopub.status.idle": "2022-11-06T16:57:56.152440Z",
     "shell.execute_reply": "2022-11-06T16:57:56.151119Z",
     "shell.execute_reply.started": "2022-11-06T16:57:56.108498Z"
    }
   },
   "outputs": [],
   "source": [
    "# Some Information\n",
    "credit_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "\n",
    "All columns except for `Time` and `Amount` are transformed by **PCA** and have been **Scaled**.\n",
    "\n",
    "Now we have to **PCA** transform and **Scale** these Columns. But before we do anything like this, we'll do some Exploratory Data Analysis (EDA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Some Description\n",
    "credit_df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "\n",
    "There isn't much to say. The features `V1-V28` are anonymous and we have no information whatsoever. This is so because these columns have some confidential information that cannot be disclosed to the general public. But these columns are well-processed (PCA Transformation, Dimensiality Reduction and Scaling), so no worries.\n",
    "\n",
    "We just need to deal with the **Time** and the **Amount** column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **EDA**\n",
    "* Look at the distribution of the `Time`, `Amount` and `Class` column\n",
    "* Experience the horrible imbalancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Time\n",
    "px.histogram(x=credit_df[\"Time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Time\n",
    "px.histogram(x=credit_df[\"Amount\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "\n",
    "Most values are around 0-100, and there are rare cases with more than 5k. But we can't consider them as outliers as it is very much possible to transfer over 5k to anyone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frauds and Non-Frauds\n",
    "plt.figure(figsize=(8, 5), dpi=120)\n",
    "credit_df.Class.value_counts().plot(kind=\"pie\", explode=[0, 0.1], shadow=True, startangle=140, autopct='%1.1f%%')\n",
    "plt.legend(labels=['Normal','Fraud'])\n",
    "plt.title('\"Fraud\" Distribution')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "\n",
    "So as you can see, there is only 0.2% fraud (570 Samples from 284,807 entries), which is a severe imbalance. If we train our model just like this, there is no chance we'll ever predict a **FRAUD** case. So we'll have to deal with this and this project is mainly about this topic - Dealing with Imbalanced Classification!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relation of Non-Frauds and Frauds with Transaction Time\n",
    "values = credit_df[\"Class\"].value_counts().index\n",
    "figure, (non_fraud, fraud) = plt.subplots(2,1, sharex=True, figsize=(15, 10))\n",
    "\n",
    "non_fraud.hist((credit_df[\"Time\"]/60/60)[credit_df[\"Class\"] == 0], bins=50, color=\"lightgreen\")\n",
    "non_fraud.set_title(\"Class = NON-FRAUD\")\n",
    "\n",
    "fraud.hist((credit_df[\"Time\"]/60/60)[credit_df[\"Class\"] ==1 ], bins=50, color=\"salmon\")\n",
    "fraud.set_title(\"Class = FRAUD\")\n",
    "\n",
    "plt.xticks(np.arange(0,54,6))\n",
    "plt.xlim([0,48])\n",
    "plt.xlabel(\"Time after first transaction (HOURS)\")\n",
    "plt.ylabel('Number of Transactions')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "As you can see, the number of transactions for genuine users take a hit during late night and early morning hours. It also makes sense since most people sleep during this. On the contrary, for fraudulent transactions, the number sees sharp spikes during late hours, and during the daytime, the count is significantly less.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Cleaning Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a copy and do all the wrangling stuff on there so we have our orignal dataset preserved\n",
    "credit_df_copy = credit_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_df_copy.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No **NULL** values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicating Data (Number of Columns)\n",
    "print(f\"Non-Frauds: {credit_df_copy[credit_df_copy.Class == 0].duplicated().sum()}\")\n",
    "print(f\"Frauds: {credit_df_copy[credit_df_copy.Class == 1].duplicated().sum()}\")\n",
    "print(\"*\" * 100)\n",
    "\n",
    "# Drop\n",
    "credit_df_copy.drop_duplicates(inplace=True)\n",
    "print(\"Dropped Succesfully\")\n",
    "print(\"*\" * 100)\n",
    "\n",
    "# Check\n",
    "print(f\"Non-Frauds: {credit_df_copy[credit_df_copy.Class == 0].duplicated().sum()}\")\n",
    "print(f\"Frauds: {credit_df_copy[credit_df_copy.Class == 1].duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding outliers, we'll not deal with them. Becuase all is possible. The amount could be easily over 5k and the time could be more becuase of internet or any technical issue. So I don't think there will be any outliers as this dataset seems to be constructed by something automated, and not manual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Pre-Processing**\n",
    "\n",
    "* PCA Transforming the `Time` & `Amount` columns\n",
    "* Using the `RobustScaler()` to scale the `Time` & `Amount` columns\n",
    "* Using `SMOTE` technique to solve the imbalancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA transformations\n",
    "pca = PCA(n_components = 2)\n",
    "columns = credit_df_copy[[\"Time\", \"Amount\"]]\n",
    "pca.fit(columns)\n",
    "credit_df_copy[[\"Time\", \"Amount\"]] = pca.transform(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling with the Robust Scaler\n",
    "transformer = RobustScaler().fit(columns)\n",
    "credit_df_copy[[\"Time\", \"Amount\"]] = transformer.transform(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using SMOTE to balance the data\n",
    "X = credit_df_copy.drop('Class', axis = 1)\n",
    "y = credit_df_copy['Class']\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X, y = smote.fit_resample(X, y)\n",
    "\n",
    "# Plot the results\n",
    "fig = px.pie(values=y.value_counts(), \n",
    "             width=800, height=400, \n",
    "             title=\"Data Balance\",\n",
    "             color_discrete_sequence=[\"skyblue\",\"black\"])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Model: Training & Evaluation**\n",
    "With our dataset prepared, the next step is to train and evaluate multiple machine learning models to determine the most effective approach for credit card fraud detection. Given the severe class imbalance, choosing the right model and handling data distribution carefully is crucial.\n",
    "\n",
    "* **Splitting the Data**: To ensure a fair evaluation, we will split the dataset into training and testing sets;\n",
    "\n",
    "Training Set: Used to train the model.\n",
    "Testing Set: Used to evaluate the modelâ€™s performance on unseen data.\n",
    "Since fraud cases are rare, we must carefully balance the dataset to prevent the model from predicting only non-fraudulent transactions.\n",
    "\n",
    "* **Trying Out Different Models** : We will experiment with multiple supervised learning algorithms to identify the best-performing classifier. The models weâ€™ll test include:\n",
    "\n",
    "    1. Logistic Regression: A simple yet effective baseline model for classification tasks. Works well with imbalanced data when combined with techniques like class weighting.\n",
    "    2. Naive Bayes (GaussianNB): A probabilistic model that assumes feature independence. Can be useful for high-dimensional datasets like ours.\n",
    "    3. Random Forest Classifier: An ensemble learning technique that creates multiple decision trees. Known for handling imbalanced datasets better than single-tree models.  \n",
    "    4. K-Neighbors Classifier: A distance-based algorithm that classifies a point based on its nearest neighbors. May struggle with large datasets due to computational complexity.\n",
    "    5. XGBoost Classifier: A powerful gradient boosting algorithm known for handling imbalanced data effectively. Regularization features prevent overfitting.\n",
    "\n",
    "* **Model Comparison & Selection** : Each model will be evaluated using the AUPRC (Area Under Precision-Recall Curve) and other relevant metrics to ensure accurate fraud detection. Based on performance, we will select the best-performing model for deployment.\n",
    "By testing multiple models and comparing their results, we aim to develop a robust fraud detection system that effectively identifies fraudulent transactions while minimizing false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(f\"\"\"Data Splitted. Here are the Stats:\n",
    "\n",
    "Rows in X_train: {X_train.shape[0]}\n",
    "Rows in y_train: {y_train.shape[0]}\n",
    "\n",
    "Rows in X_test: {X_test.shape[0]}\n",
    "Rows in y_test: {y_test.shape[0]} \n",
    "\n",
    "Columns in X_train & X_test are 3\n",
    "Columns in y_train & y_test is only 1 - the TARGET column (i.e Class)\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train , y_train)\n",
    "classifier_score = classifier.score(X_test , y_test).round(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "dt =DecisionTreeClassifier(max_features=8 , max_depth=6)\n",
    "dt.fit(X_train , y_train)\n",
    "dt_score = dt.score(X_test , y_test).round(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier\n",
    "Rclf = RandomForestClassifier(max_features=8 , max_depth=6)\n",
    "Rclf.fit(X_train, y_train)\n",
    "Rclf_score = Rclf.score(X_test, y_test).round(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression(C = 100, max_iter=1000)\n",
    "lr.fit(X_train , y_train)\n",
    "lr_score = lr.score(X_test , y_test).round(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Nearest\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "knn.fit(X_train, y_train)\n",
    "knn_score = knn.score(X_test, y_test).round(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train , y_train)\n",
    "xgb_score = xgb.score(X_test, y_test).round(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Metrics**\n",
    "\n",
    "* Accuracy\n",
    "* F-1 Score\n",
    "* Precision Score\n",
    "* Recall Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comparison = {}\n",
    "names = [\"Decision Tree\", \"Naive\", \"Random Forest\", \"KNN\", \"Logistic Regression\", \"XGboost\"]\n",
    "models = [classifier, dt, Rclf, lr, knn, xgb]\n",
    "results = {}\n",
    "\n",
    "# Make Predictions\n",
    "for model in models:\n",
    "    results[str(model).split(\"(\")[0]] = [model.predict(X_test)]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the scores of the metrics\n",
    "for model, preds in results.items():\n",
    "    model_comparison[model] = [\n",
    "                            round(accuracy_score(y_test, pd.DataFrame(preds).T), 2),\n",
    "                            round(f1_score(y_test, pd.DataFrame(preds).T,average='weighted'), 2),\n",
    "                            round(precision_score(y_test, pd.DataFrame(preds).T), 2),\n",
    "                            round(recall_score(y_test, pd.DataFrame(preds).T), 2),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(model_comparison, index=[\"Accuracy\", \"F-1 Score\", \"Precision Score\", \"Recall Score\"])\n",
    "results_df.style.format(\"{:.2%}\").background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation Scores\n",
    "classifier_cr = cross_val_score(classifier, credit_df_copy.drop(\"Class\", axis=1), credit_df_copy[\"Class\"], cv=5).mean()\n",
    "dt_cr = cross_val_score(dt, credit_df_copy.drop(\"Class\", axis=1), credit_df_copy[\"Class\"], cv=5).mean()\n",
    "Rclf_cr = cross_val_score(Rclf, credit_df_copy.drop(\"Class\", axis=1), credit_df_copy[\"Class\"], cv=5).mean()\n",
    "lr_cr = cross_val_score(lr, cre`dit_df_copy.drop(\"Class\", axis=1), credit_df_copy[\"Class\"], cv=5).mean()\n",
    "knn_cr = cross_val_score(knn, credit_df_copy.drop(\"Class\", axis=1), credit_df_copy[\"Class\"], cv=5).mean()\n",
    "xgb_cr = cross_val_score(xgb, credit_df_copy.drop(\"Class\", axis=1), credit_df_copy[\"Class\"], cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation Scores in a Plot\n",
    "cross_validated_scores = [classifier_cr, dt_cr, Rclf_cr, lr_cr, knn_cr, xgb_cr]\n",
    "cross_validated_scores = pd.DataFrame(cross_validated_scores, index=[\"GaussianNB\", \n",
    "                                            \"DecisionTreeClassifier\", \n",
    "                                            \"RandomForestClassifier\",\n",
    "                                            \"LogisticRegression\",\n",
    "                                            \"KNeighborsClassifier\", \n",
    "                                            \"XGBClassifier\"])\n",
    "cross_validated_scores.rename(columns={0 : \"Score\"}, inplace=True)\n",
    "cross_validated_scores.plot(kind=\"bar\", figsize=(10, 5), color=[\"salmon\"])\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Conclusion**\n",
    "\n",
    "This project successfully explored the challenge of credit card fraud detection, a real-world problem where fraudulent transactions are extremely rare compared to legitimate ones. The key takeaway from this analysis is that handling class imbalance is crucial to building an effective fraud detection system.\n",
    "\n",
    "**Key Learnings & Takeaways**\n",
    "* Data Preprocessing & Feature Engineering\n",
    " 1. The dataset consisted of numerical features obtained from PCA transformation, with â€˜Amountâ€™ and â€˜Timeâ€™ being the only raw variables.\n",
    " 2. Proper data cleaning and exploration helped in understanding patterns and distributions.\n",
    "\n",
    "* **Handling Class Imbalance**\n",
    "1. Fraudulent transactions accounted for only 0.172% of the total dataset, making it highly skewed.\n",
    "2. We applied SMOTE (Synthetic Minority Over-sampling Technique) and other resampling techniques to balance the data and improve model performance.\n",
    "\n",
    "* **Model Selection & Performance Evaluation**\n",
    "Multiple machine learning models, including Logistic Regression, NaÃ¯ve Bayes, Random Forest, K-Nearest Neighbors, and XGBoost, were tested.\n",
    "AUPRC (Area Under the Precision-Recall Curve) was used as the primary evaluation metric, ensuring meaningful results for fraud detection.\n",
    "The best-performing model achieved an optimal balance between precision and recall, reducing false positives while effectively identifying fraudulent transactions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
